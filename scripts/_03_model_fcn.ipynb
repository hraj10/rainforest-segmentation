{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc85b38",
   "metadata": {},
   "source": [
    "# Fully Convolutional Network (FCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02697147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import _02c_read_datasets\n",
    "import _02_evaluate_model\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, jaccard_score\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0574d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "epochs = 20\n",
    "batches = 16\n",
    "input_width = 256\n",
    "input_shape = (256,256,4)\n",
    "shuffled = True\n",
    "augment = False #{True, False}\n",
    "if augment:\n",
    "    augmentation_settings = {\n",
    "    \"flip_left_right\": 0,\n",
    "    \"flip_up_down\": 0,\n",
    "    \"gaussian_blur\": 0.2,\n",
    "    \"random_noise\": 0.0,\n",
    "    \"random_brightness\": 0.5,\n",
    "    \"random_contrast\": 0.5}\n",
    "else:\n",
    "    augmentation_settings = None\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = _02c_read_datasets.load_datasets(augmented = augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61b4e023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 256, 256, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 256, 256, 32  1184        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 256, 256, 32  128        ['conv2d_34[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 256, 256, 32  9248        ['batch_normalization_33[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 256, 256, 32  128        ['conv2d_35[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 128, 128, 32  0          ['batch_normalization_34[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 128, 128, 64  18496       ['max_pooling2d_8[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 128, 128, 64  256        ['conv2d_36[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 128, 128, 64  36928       ['batch_normalization_35[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 128, 128, 64  256        ['conv2d_37[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 64, 64, 64)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 64, 64, 128)  73856       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 64, 64, 128)  512        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 64, 64, 128)  147584      ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 64, 64, 128)  512        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 32, 32, 128)  0          ['batch_normalization_38[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 32, 32, 256)  295168      ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 32, 32, 256)  590080      ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 16, 16, 256)  0          ['batch_normalization_40[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 16, 16, 512)  1180160     ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 16, 16, 512)  2359808     ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 512)  0          ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 32, 32, 256)  524544      ['up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 512)  0           ['batch_normalization_43[0][0]', \n",
      "                                                                  'batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 32, 32, 256)  1179904     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_44 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 32, 32, 256)  590080      ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 256)  0          ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 64, 64, 128)  131200      ['up_sampling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 64, 64, 128)  512        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 256)  0           ['batch_normalization_46[0][0]', \n",
      "                                                                  'batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 64, 64, 128)  295040      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 64, 64, 128)  512        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 64, 64, 128)  147584      ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 64, 64, 128)  512        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 12  0          ['batch_normalization_48[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 128, 128, 64  32832       ['up_sampling2d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 128, 128, 64  256        ['conv2d_50[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 128, 128, 12  0           ['batch_normalization_49[0][0]', \n",
      "                                8)                                'batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 128, 128, 64  73792       ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 128, 128, 64  256        ['conv2d_51[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 128, 128, 64  36928       ['batch_normalization_50[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 128, 128, 64  256        ['conv2d_52[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 64  0          ['batch_normalization_51[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 256, 256, 32  8224        ['up_sampling2d_8[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 256, 256, 32  128        ['conv2d_53[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256, 256, 64  0           ['batch_normalization_52[0][0]', \n",
      "                                )                                 'batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 256, 256, 32  18464       ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 256, 256, 32  128        ['conv2d_54[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 256, 256, 32  9248        ['batch_normalization_53[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 256, 256, 32  128        ['conv2d_55[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 256, 256, 1)  33          ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,774,081\n",
      "Trainable params: 7,767,233\n",
      "Non-trainable params: 6,848\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def fcn_model(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoding\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "    # Decoding\n",
    "    \n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    up6 = Conv2D(256, (2, 2), activation='relu', padding='same')(up6)\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    merge6 = Concatenate(axis=3)([up6, conv4])\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    up7 = Conv2D(128, (2, 2), activation='relu', padding='same')(up7)\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    merge7 = Concatenate(axis=3)([up7, conv3])\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    up8 = Conv2D(64, (2, 2), activation='relu', padding='same')(up8)\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    merge8 = Concatenate(axis=3)([up8, conv2])\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    \n",
    "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    up9 = Conv2D(32, (2, 2), activation='relu', padding='same')(up9)\n",
    "    up9 = BatchNormalization()(up9)\n",
    "    merge9 = Concatenate(axis=3)([up9, conv1])\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = fcn_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- create directories\n",
    "out_dir = '../results/' + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + '_FCN/'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    os.makedirs(out_dir + '/plots')\n",
    "    os.makedirs(out_dir + '/weights')\n",
    "    os.makedirs(out_dir + '/predictions')\n",
    "    os.makedirs(out_dir + '/bestweights')\n",
    "\n",
    "    \n",
    "# Define the path where you want to save the weights\n",
    "checkpoint_path = out_dir + 'bestweights/' \n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(train_dataset, validation_data=val_dataset,epochs=epochs,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0eb5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- save results\n",
    "\n",
    "\n",
    "# Load the saved, optimal  weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Compile the model with the same optimizer and loss function used during training\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"accuracy\"])\n",
    "model.save_weights(out_dir+'model.hdf5')\n",
    "\n",
    "\n",
    "# ----------- plot the training and validation loss\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.savefig(out_dir + '/plots/' + 'loss.png')\n",
    "\n",
    "# ----------- plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(out_dir + '/plots/' + 'accuracy.png')\n",
    "\n",
    "# ----------- save weights\n",
    "model.save(out_dir + '/weights/' + 'model.h5')\n",
    "\n",
    "# ----------- save predictions\n",
    "def visualize_predictions(index, test_dataset, out_dir):\n",
    "    test_data_iter = iter(itertools.cycle(test_dataset))\n",
    "\n",
    "    for i in range(index + 1):\n",
    "        image_batch, label_batch = next(test_data_iter)\n",
    "\n",
    "    wrapped_index = index % batches\n",
    "    image = image_batch[wrapped_index].numpy()\n",
    "    \n",
    "    image_rgb = np.stack(\n",
    "        (\n",
    "            (image[:,:,0] - np.min(image[:,:,0])) * 255.0 / (np.max(image[:,:,0]) - np.min(image[:,:,0])),\n",
    "            (image[:,:,1] - np.min(image[:,:,1])) * 255.0 / (np.max(image[:,:,1]) - np.min(image[:,:,1])),\n",
    "            (image[:,:,2] - np.min(image[:,:,2])) * 255.0 / (np.max(image[:,:,2]) - np.min(image[:,:,2]))\n",
    "        ),\n",
    "        axis=-1\n",
    "    ).astype(np.uint8)\n",
    "    prediction = model.predict(np.expand_dims(image, axis=0))[0]\n",
    "    ground_truth = label_batch[wrapped_index].numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10, 10));\n",
    "    ax[0,0].imshow(image_rgb);\n",
    "    ax[0,0].set_title(\"Input Image\");\n",
    "    ax[0,1].imshow(np.squeeze(ground_truth), cmap='gray');\n",
    "    ax[0,1].set_title(\"Ground Truth\");\n",
    "    ax[1,0].imshow(np.squeeze(prediction), cmap='gray')\n",
    "    ax[1,0].set_title(\"Prediction\")\n",
    "    ax[1,1].imshow(np.squeeze(prediction) > 0.5, cmap='gray')\n",
    "    ax[1,1].set_title(\"Prediction (binary)\")\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax[i,j].axis('off')\n",
    "            \n",
    "    \n",
    "    plt.savefig(out_dir + '/predictions/' + 'comparison_' + str(index) + '.png');\n",
    "for i in range(80):\n",
    "    visualize_predictions(i, test_dataset, out_dir)\n",
    "\n",
    "# ----------- save metrics\n",
    "\n",
    "model_info = _02_evaluate_model.evaluate_model(\n",
    "    \"FCN\", \n",
    "    test_dataset, \n",
    "    model, \n",
    "    input_shape, \n",
    "    shuffled, \n",
    "    batches, \n",
    "    epochs, \n",
    "    augmentation_settings=augmentation_settings, \n",
    "    threshold=0.5)\n",
    "df = pd.DataFrame(model_info)\n",
    "df.to_csv(os.path.join(out_dir, 'metrics.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59342555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(index, test_dataset, out_dir, batches = 16):\n",
    "    \n",
    "    dir = \"image_\" + str(index)\n",
    "    if not os.path.exists(out_dir + '/predictions/' + dir + '/'):\n",
    "        os.makedirs(out_dir + '/predictions/' + dir + '/')\n",
    "        os.makedirs(out_dir + '/predictions/' + dir + '/input_image')\n",
    "        os.makedirs(out_dir + '/predictions/' + dir + '/ground_truth')\n",
    "        os.makedirs(out_dir + '/predictions/' + dir + '/prediction')\n",
    "        os.makedirs(out_dir + '/predictions/' + dir + '/prediction_binary')\n",
    "    \n",
    "    test_data_iter = iter(itertools.cycle(test_dataset))\n",
    "\n",
    "    for i in range(index + 1):\n",
    "        image_batch, label_batch = next(test_data_iter)\n",
    "\n",
    "    wrapped_index = index % 16\n",
    "    image = image_batch[wrapped_index].numpy()\n",
    "    image_rgb = np.stack(\n",
    "        (\n",
    "            (image[:,:,0] - np.min(image[:,:,0])) * 255.0 / (np.max(image[:,:,0]) - np.min(image[:,:,0])),\n",
    "            (image[:,:,1] - np.min(image[:,:,1])) * 255.0 / (np.max(image[:,:,1]) - np.min(image[:,:,1])),\n",
    "            (image[:,:,2] - np.min(image[:,:,2])) * 255.0 / (np.max(image[:,:,2]) - np.min(image[:,:,2]))\n",
    "        ),\n",
    "        axis=-1\n",
    "    ).astype(np.uint8)\n",
    "\n",
    "    prediction = model.predict(np.expand_dims(image, axis=0))[0]\n",
    "    plt.imsave(out_dir + '/predictions/' + dir + '/input_image/' + str(index) + '.png', image_rgb)\n",
    "\n",
    "    ground_truth = label_batch[wrapped_index].numpy()\n",
    "    plt.imsave(out_dir + '/predictions/' + dir + '/ground_truth/' + str(index) + '.png', np.squeeze(ground_truth), cmap='gray')\n",
    "\n",
    "    plt.imsave(out_dir + '/predictions/' + dir + '/prediction/' + str(index) + '.png', np.squeeze(prediction), cmap='gray')\n",
    "\n",
    "    prediction_binary = np.where(prediction > 0.5, 1, 0)\n",
    "    plt.imsave(out_dir + '/predictions/' + dir + '/prediction_binary/' + str(index) + '.png', np.squeeze(prediction_binary), cmap='gray')\n",
    "\n",
    "for i in range(80):\n",
    "    visualize_predictions(i, test_dataset, out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
